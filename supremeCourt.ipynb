{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 258,
   "id": "c6cafb22",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\gorka\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\gorka\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\gorka\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package omw-1.4 to\n",
      "[nltk_data]     C:\\Users\\gorka\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "\n",
    "import pandas as pd\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "from nltk.stem import PorterStemmer\n",
    "\n",
    "import gensim\n",
    "import gensim.corpora as corpora\n",
    "from gensim.utils import simple_preprocess\n",
    "from gensim.models import LdaModel\n",
    "from gensim.models import CoherenceModel\n",
    "\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n",
    "nltk.download('omw-1.4')\n",
    "# load all metadata\n",
    "\n",
    "stop_words = set(stopwords.words(\"english\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "id": "23cfbe2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Cargamos los datos\n",
    "#Cogemos las 100 primeras descripciones como prueba\n",
    "data = pd.read_csv('justice.csv')\n",
    "x_train = data['facts']\n",
    "y_train1 = data['first_party_winner']\n",
    "y_train2 = data['issue_area']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "id": "a3406719",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Elimina signos de puntuacion y todo a minusculas\n",
    "def sent_to_words(sentences):\n",
    "    for sentence in sentences:\n",
    "        yield (gensim.utils.simple_preprocess(str(sentence), deacc=True))  # deacc=True removes punctuations\n",
    "\n",
    "data_words = list(sent_to_words(x_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "id": "ef373b88",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Eliminamos las stop words\n",
    "def remove_stopwords(texts):\n",
    "    return [[word for word in simple_preprocess(str(doc)) if word not in stop_words] for doc in texts]\n",
    "\n",
    "data_words_nostops = remove_stopwords(data_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "id": "3d01834d",
   "metadata": {},
   "outputs": [],
   "source": [
    "lem = WordNetLemmatizer()\n",
    "ps = PorterStemmer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "id": "c6f5abd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Lematizamos\n",
    "def lemmatization(texts):\n",
    "    texts_out = []\n",
    "    for text in texts:\n",
    "        lemText = []\n",
    "        for sent in text:\n",
    "            stemmed = ps.stem(sent)\n",
    "            lemText.append(lem.lemmatize(stemmed))\n",
    "        texts_out.append(lemText)\n",
    "    return texts_out\n",
    "\n",
    "data_lemmatized = lemmatization(data_words_nostops)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "id": "ed848d78",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic: 0 (0, '0.035*\"patent\" + 0.020*\"use\" + 0.019*\"court\" + 0.017*\"infring\" + 0.012*\"appeal\" + 0.010*\"district\" + 0.010*\"feder\" + 0.009*\"product\" + 0.009*\"copyright\" + 0.009*\"inc\"')\n",
      "Topic: 1 (1, '0.043*\"m\" + 0.027*\"st\" + 0.023*\"naacp\" + 0.017*\"basic\" + 0.017*\"dr\" + 0.015*\"levin\" + 0.010*\"war\" + 0.009*\"zenith\" + 0.009*\"sprint\" + 0.009*\"easement\"')\n",
      "Topic: 2 (2, '0.085*\"court\" + 0.031*\"appeal\" + 0.028*\"state\" + 0.028*\"petit\" + 0.024*\"feder\" + 0.023*\"file\" + 0.022*\"district\" + 0.020*\"counsel\" + 0.020*\"habea\" + 0.018*\"deni\"')\n",
      "Topic: 3 (3, '0.046*\"court\" + 0.023*\"arbitr\" + 0.018*\"district\" + 0.018*\"claim\" + 0.017*\"carolina\" + 0.016*\"state\" + 0.016*\"north\" + 0.015*\"feder\" + 0.014*\"agreement\" + 0.013*\"law\"')\n",
      "Topic: 4 (4, '0.022*\"state\" + 0.018*\"land\" + 0.016*\"act\" + 0.013*\"tribe\" + 0.011*\"court\" + 0.010*\"servic\" + 0.010*\"regul\" + 0.009*\"unit\" + 0.009*\"nation\" + 0.009*\"feder\"')\n",
      "Topic: 5 (5, '0.043*\"sentenc\" + 0.043*\"juri\" + 0.033*\"death\" + 0.027*\"murder\" + 0.027*\"trial\" + 0.017*\"convict\" + 0.015*\"court\" + 0.014*\"judg\" + 0.014*\"found\" + 0.012*\"evid\"')\n",
      "Topic: 6 (6, '0.090*\"florida\" + 0.030*\"montana\" + 0.029*\"colorado\" + 0.019*\"water\" + 0.016*\"master\" + 0.016*\"ford\" + 0.016*\"fish\" + 0.015*\"compact\" + 0.015*\"river\" + 0.014*\"mexico\"')\n",
      "Topic: 7 (7, '0.034*\"court\" + 0.018*\"trial\" + 0.017*\"convict\" + 0.013*\"charg\" + 0.012*\"juri\" + 0.011*\"appeal\" + 0.011*\"violat\" + 0.010*\"state\" + 0.009*\"defend\" + 0.009*\"indict\"')\n",
      "Topic: 8 (8, '0.043*\"court\" + 0.017*\"district\" + 0.016*\"tax\" + 0.015*\"appeal\" + 0.013*\"circuit\" + 0.012*\"feder\" + 0.011*\"claim\" + 0.010*\"state\" + 0.010*\"act\" + 0.010*\"file\"')\n",
      "Topic: 9 (9, '0.027*\"court\" + 0.021*\"claim\" + 0.015*\"district\" + 0.014*\"appeal\" + 0.013*\"circuit\" + 0.010*\"dismiss\" + 0.009*\"file\" + 0.009*\"feder\" + 0.009*\"act\" + 0.008*\"action\"')\n",
      "Topic: 10 (10, '0.063*\"em\" + 0.021*\"href\" + 0.017*\"davi\" + 0.016*\"http\" + 0.016*\"case\" + 0.014*\"org\" + 0.014*\"oyez\" + 0.014*\"www\" + 0.012*\"abort\" + 0.011*\"nevada\"')\n",
      "Topic: 11 (11, '0.051*\"state\" + 0.030*\"court\" + 0.018*\"district\" + 0.015*\"act\" + 0.014*\"law\" + 0.013*\"vote\" + 0.012*\"amend\" + 0.012*\"suprem\" + 0.012*\"parti\" + 0.011*\"violat\"')\n",
      "Topic: 12 (12, '0.031*\"benefit\" + 0.027*\"plan\" + 0.026*\"employe\" + 0.023*\"insur\" + 0.018*\"health\" + 0.016*\"secur\" + 0.015*\"retir\" + 0.013*\"settlement\" + 0.012*\"act\" + 0.012*\"court\"')\n",
      "Topic: 13 (13, '0.075*\"school\" + 0.046*\"child\" + 0.032*\"student\" + 0.022*\"district\" + 0.020*\"educ\" + 0.017*\"parent\" + 0.014*\"public\" + 0.011*\"mother\" + 0.011*\"state\" + 0.010*\"teacher\"')\n",
      "Topic: 14 (14, '0.027*\"court\" + 0.020*\"compani\" + 0.014*\"damag\" + 0.014*\"em\" + 0.013*\"class\" + 0.013*\"district\" + 0.012*\"price\" + 0.011*\"act\" + 0.010*\"california\" + 0.009*\"action\"')\n",
      "Topic: 15 (15, '0.072*\"court\" + 0.026*\"appeal\" + 0.025*\"em\" + 0.019*\"suprem\" + 0.013*\"state\" + 0.012*\"case\" + 0.012*\"decis\" + 0.012*\"district\" + 0.011*\"circuit\" + 0.011*\"rule\"')\n",
      "Topic: 16 (16, '0.029*\"court\" + 0.028*\"sentenc\" + 0.025*\"convict\" + 0.017*\"appeal\" + 0.013*\"district\" + 0.013*\"circuit\" + 0.012*\"guilti\" + 0.011*\"immigr\" + 0.011*\"posse\" + 0.011*\"state\"')\n",
      "Topic: 17 (17, '0.039*\"court\" + 0.036*\"district\" + 0.016*\"discrimin\" + 0.016*\"plan\" + 0.011*\"employ\" + 0.011*\"appeal\" + 0.011*\"titl\" + 0.010*\"racial\" + 0.009*\"equal\" + 0.008*\"file\"')\n",
      "Topic: 18 (18, '0.020*\"court\" + 0.017*\"violat\" + 0.015*\"citi\" + 0.015*\"union\" + 0.014*\"amend\" + 0.012*\"first\" + 0.011*\"law\" + 0.010*\"public\" + 0.010*\"employe\" + 0.009*\"labor\"')\n",
      "Topic: 19 (19, '0.033*\"offic\" + 0.027*\"polic\" + 0.021*\"court\" + 0.017*\"search\" + 0.016*\"arrest\" + 0.011*\"evid\" + 0.010*\"warrant\" + 0.009*\"car\" + 0.008*\"appeal\" + 0.008*\"found\"')\n"
     ]
    }
   ],
   "source": [
    "#Vectorizar\n",
    "#Topic modeling\n",
    "id2word = corpora.Dictionary(data_lemmatized)\n",
    "texts = data_lemmatized\n",
    "corpus = [id2word.doc2bow(text) for text in texts]\n",
    "#lda = LdaModel(corpus=corpus, id2word=id2word, num_topics=20, random_state=100, update_every=1, chunksize=100, passes=20, alpha='auto',per_word_topics=True)\n",
    "#print(f\"TOPICOS --> {lda.print_topics()}\")\n",
    "\n",
    "lda_model = LdaModel(corpus=corpus, id2word=id2word, num_topics=20, random_state=100, passes=50, eval_every=None)\n",
    "count = 0\n",
    "for i in lda_model.print_topics():\n",
    "    print(\"Topic:\", count, i)\n",
    "    count += 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "id": "edf9313d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            0    1         2         3         4         5         6   \\\n",
      "0     0.000000  0.0  0.000000  0.000000  0.000000  0.118256  0.000000   \n",
      "1     0.000000  0.0  0.000000  0.000000  0.131371  0.000000  0.000000   \n",
      "2     0.000000  0.0  0.072559  0.000000  0.000000  0.000000  0.000000   \n",
      "3     0.000000  0.0  0.000000  0.000000  0.000000  0.040615  0.000000   \n",
      "4     0.182056  0.0  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
      "...        ...  ...       ...       ...       ...       ...       ...   \n",
      "3298  0.000000  0.0  0.049182  0.000000  0.000000  0.000000  0.000000   \n",
      "3299  0.087502  0.0  0.087258  0.027243  0.000000  0.000000  0.000000   \n",
      "3300  0.000000  0.0  0.000000  0.021977  0.148934  0.000000  0.010125   \n",
      "3301  0.000000  0.0  0.000000  0.179831  0.000000  0.000000  0.303487   \n",
      "3302  0.086962  0.0  0.000000  0.115084  0.266418  0.000000  0.000000   \n",
      "\n",
      "            7         8         9         10        11   12        13   14  \\\n",
      "0     0.000000  0.124620  0.053426  0.000000  0.215596  0.0  0.000000  0.0   \n",
      "1     0.000000  0.000000  0.000000  0.124637  0.000000  0.0  0.490019  0.0   \n",
      "2     0.207997  0.000000  0.000000  0.000000  0.000000  0.0  0.000000  0.0   \n",
      "3     0.000000  0.145463  0.331353  0.000000  0.160733  0.0  0.091830  0.0   \n",
      "4     0.000000  0.000000  0.000000  0.000000  0.000000  0.0  0.192812  0.0   \n",
      "...        ...       ...       ...       ...       ...  ...       ...  ...   \n",
      "3298  0.088936  0.000000  0.000000  0.000000  0.000000  0.0  0.000000  0.0   \n",
      "3299  0.000000  0.000000  0.000000  0.000000  0.000000  0.0  0.000000  0.0   \n",
      "3300  0.000000  0.000000  0.188173  0.000000  0.107151  0.0  0.000000  0.0   \n",
      "3301  0.191345  0.000000  0.000000  0.291995  0.000000  0.0  0.000000  0.0   \n",
      "3302  0.000000  0.273369  0.000000  0.000000  0.249738  0.0  0.000000  0.0   \n",
      "\n",
      "            15        16        17        18        19  \n",
      "0     0.000000  0.000000  0.207814  0.266281  0.000000  \n",
      "1     0.242537  0.000000  0.000000  0.000000  0.000000  \n",
      "2     0.301503  0.000000  0.000000  0.000000  0.400543  \n",
      "3     0.000000  0.110432  0.100978  0.000000  0.000000  \n",
      "4     0.222726  0.000000  0.000000  0.300046  0.074557  \n",
      "...        ...       ...       ...       ...       ...  \n",
      "3298  0.318983  0.537769  0.000000  0.000000  0.000000  \n",
      "3299  0.000000  0.765032  0.000000  0.000000  0.024235  \n",
      "3300  0.000000  0.054534  0.000000  0.000000  0.463083  \n",
      "3301  0.000000  0.000000  0.000000  0.000000  0.000000  \n",
      "3302  0.000000  0.000000  0.000000  0.000000  0.000000  \n",
      "\n",
      "[3303 rows x 20 columns]\n"
     ]
    }
   ],
   "source": [
    "#Hay que cambiar el n_topics por el numero de topics del LDA\n",
    "n_topics = 20\n",
    "vectorized = []\n",
    "count = 0\n",
    "\n",
    "for i in lda_model[corpus]:\n",
    "    index = [0]*n_topics\n",
    "    for n in i:\n",
    "        index[n[0]] = n[1]\n",
    "    vectorized.append(index)\n",
    "vectorized = pd.DataFrame(vectorized)\n",
    "print(vectorized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before: (3303, 20)\n",
      "After: (3303, 19)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.decomposition import  PCA\n",
    "\n",
    "print(\"Before:\", vectorized.shape)\n",
    "pca = PCA(n_components='mle', svd_solver='full')\n",
    "#pca = PCA(n_components=2)\n",
    "pca.fit(vectorized)\n",
    "labels_PCA= pca.transform(vectorized)\n",
    "print(\"After:\", labels_PCA.shape)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "outputs": [],
   "source": [
    "import math\n",
    "import numpy as np\n",
    "def getDist(clust1, clust2):\n",
    "    dist = 0\n",
    "    for i in range(len(clust1)):\n",
    "        dist += math.sqrt((clust1[i] - clust2[i])**2)\n",
    "    return dist"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "outputs": [],
   "source": [
    "def getDistances(clusters):\n",
    "    distances = []\n",
    "    for clust1 in range(len(clusters)):\n",
    "        dist_clust1 = [np.NAN] * (clust1+1)\n",
    "        for clust2 in [t for t in range(len(clusters)) if t > clust1]:\n",
    "            dist_clust1.append(getDist(clusters[clust1], clusters[clust2]))\n",
    "        distances.append(np.array(dist_clust1))\n",
    "    distances = np.array(distances)\n",
    "    return distances\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "clusters = labels_PCA.copy()\n",
    "n=10\n",
    "distances = getDistances(clusters)\n",
    "k_clusters = [[i] for i in range(len(clusters))]\n",
    "\n",
    "while len(distances) > n:\n",
    "    ind1,ind2 = np.unravel_index(np.nanargmin(distances), distances.shape)\n",
    "    delete = max(ind1,ind2)\n",
    "    replace = min(ind1,ind2)\n",
    "    for i in [t for t in range(len(distances)) if t != ind1 and t != ind2]:\n",
    "        if replace < i:\n",
    "            distances[replace][i] = np.nanmin([distances[ind1][i],distances[ind2][i],distances[i][ind1],distances[i][ind2]])\n",
    "\n",
    "        else:\n",
    "            distances[i][replace] = np.nanmin([distances[ind1][i],distances[ind2][i],distances[i][ind1],distances[i][ind2]])\n",
    "    distances = np.delete(distances, delete,1)\n",
    "    distances = np.delete(distances, delete,0)\n",
    "    k_clusters[replace] += k_clusters[delete]\n",
    "    k_clusters.remove(k_clusters[delete])\n",
    "\n",
    "kmeans_labels= [0] * len(clusters)\n",
    "i = 0\n",
    "for k in k_clusters:\n",
    "    for c in k:\n",
    "        kmeans_labels[c] = i\n",
    "    i += 1\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "samples = 30\n",
    "# Dibujar los puntos en el espacio, color: cluster, etiqueta-numérica: clase\n",
    "# Color del punto: cluster\n",
    "sc = plt.scatter(labels_PCA[:samples,0],labels_PCA[:samples,1], cmap=plt.cm.get_cmap('nipy_spectral', 20),c=kmeans_labels[:samples])\n",
    "plt.colorbar()\n",
    "# Etiqueta numérica: clase\n",
    "for i in range(samples):\n",
    "    plt.text(labels_PCA[i,0],labels_PCA[i,1], y_train2[i])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}